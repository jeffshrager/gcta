{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information gain for the linear mixed effects patient outcomes model\n",
    "\n",
    "All other considerations being equal, which treatment, $x_\\mathrm{tx}$, should a patient with biomarkers $x_\\mathrm{bm}$ take to best update our understanding of how to predict patient outcomes, $y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher information\n",
    "If we observed the actual outcome of a treatment, then we could compute a measure of information gain through the Kullback-Liebler divergence (or relative entropy) of the posterior, $P(\\theta | y)$, with respect to the prior, $P(\\theta)$.\n",
    "\n",
    "$$ D\\big[ P(\\theta | y) \\ || \\ P(\\theta) \\big] = \\int P(\\theta | y) \\ \\log\\left(\\frac{P(\\theta | y)}{P(\\theta)}\\right) \\ \\mathrm{d}\\theta $$\n",
    "\n",
    "The relative entropy measures the information lost by approximating $P(\\theta | y)$ with $P(\\theta)$, and thus it provides a nice way of measuring the usefulness of an experiment after observing the results.  However we'd like a way to quantify the potential usefulness of an experiment prior to observing the results.\n",
    "\n",
    "The Fisher information (hereafter, just information) is a measure of the maximum extent to which data can update a model.\n",
    "\n",
    "Formally, if we have a likelihood $f(y|\\theta)$ of data, $y$, given model parameters, $\\theta$, then the information, $I(\\theta)$ provides a lower bound on the variance of the any estimator for the model parameters:\n",
    "\n",
    "$$ \\mathrm{Cov}(\\hat{\\theta}) \\geq I^{-1}(\\theta) $$\n",
    "\n",
    "In the case of a model with more than one parameters, the information is a matrix whose inverse is the lower bound of the parameter covariance matrix.\n",
    "\n",
    "The information is defined as\n",
    "\n",
    "$$ I(\\theta)_{i,j} = -\\int H_\\theta \\big[ \\log f(y | \\theta) \\big]_{i,j} \\ f(y | \\theta) \\ \\mathrm{d}y $$\n",
    "\n",
    "where $H_\\theta$ is the Hessian operator, or the matrix of second derivatives with respect to $\\theta$.  As a side note for the geometrically inclined, the information can also be seen as the curvature of the relative entropy.\n",
    "\n",
    "Notably, the information integrates over all possible results of an experiment, and so we don't need to observe the outcome of an experiment in order to compute its potential to update the model.  We will however, need to put in some assumption for the model parameters, $\\theta$.  In a Bayesian inference context, we can simply take the expectation value of $I(\\theta)$ over the prior, $P(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear mixed model for patient outcomes\n",
    "\n",
    "Let's look at the properties of the information for the patient outcomes model.\n",
    "\n",
    "As a reminder, the model predicts patient outcomes, $y$ (e.g., tumor load or Karnofsky score), given patient covariates, $x_\\mathrm{bm}$, a treatment $x_\\mathrm{tx}$, and a time after treatment, $t$.\n",
    "\n",
    "The patient outcome is assumed to be normally distributed with a mean of $\\mu = x \\cdot \\beta + z \\cdot u$ and a variance of $\\sigma^2_\\epsilon$.  \n",
    "\n",
    "$\\beta = (\\beta_0, \\beta_1, \\beta_\\mathrm{bm}, \\beta_\\mathrm{tx}, \\beta_\\mathrm{int})$ is a vector of model parameters denoting population-level or fixed effects.\n",
    "\n",
    "$x = (1, t, x_\\mathrm{bm}t, x_\\mathrm{tx}t, x_\\mathrm{int}t)$ is a vector of patient covariates formed from their biomarkers, the chosen treatment, and the time after treatment.\n",
    "\n",
    "$u = (u_0, u_1)$ is a vector of patient-level or random effects, and $z = (1, t)$ is a vector of patient-level predictors.  The patient-level effects are assumed to be drawn from a normal distribution with a mean of 0 and a covariance matrix,\n",
    "\n",
    "$$ \\Sigma_u = \\begin{pmatrix} \\sigma^2_0 & \\rho \\sigma_0 \\sigma_1 \\\\ \\rho \\sigma_0 \\sigma_1 & \\sigma^2_1 \\end{pmatrix} $$\n",
    "\n",
    "With some loss of generality but much gain in ease of computation, let's assume that there is no correlation in patient-level effects (that is, $\\rho = 0$).  Thus there are three noise terms in the model, $\\sigma^2_\\epsilon$, $\\sigma^2_0$, and $\\sigma^2_1$.\n",
    "\n",
    "Through a little gumption, we can compute the information matrix for parameters $\\theta = (\\beta, \\sigma^2)$ where $\\sigma^2 = (\\sigma^2_\\epsilon, \\sigma^2_0, \\sigma^2_1)$ as the block matrix\n",
    "\n",
    "$$ I(\\theta) = \\begin{pmatrix} I_{\\beta\\beta} & I_{\\beta\\sigma^2} \\\\ I_{\\beta\\sigma^2}^T & I_{\\sigma^2\\sigma^2} \\end{pmatrix} $$\n",
    "\n",
    "The population-level effects entries are simply given by\n",
    "\n",
    "$$ I_{\\beta\\beta, i, j} = \\frac{x_i x_j}{v} $$\n",
    "\n",
    "where $v = \\sigma^2_\\epsilon + \\sigma^2_0 + \\sigma^2_1$.\n",
    "\n",
    "The cross-terms, in $I_{\\beta\\sigma^2}$, are conveniently all zero.  The noise block is given by\n",
    "\n",
    "$$ I_{\\sigma^2\\sigma^2} = \\frac{1}{2v^2} \\begin{pmatrix} 1 & t^2 & 1 \\\\ t^2 & t^4 & t^2 \\\\ 1 & t^2 & 1 \\end{pmatrix} $$\n",
    "\n",
    "For a generalization of this calculation to non-linear mixed models with exponential family link functions, see [Wand 2007](https://www.sciencedirect.com/science/article/pii/S0047259X07000024).\n",
    "\n",
    "There are a couple rather obvious (at least in retrospect) takeaways from this calculation.  First, we need to try an experiment with specific patient covariate $x_i$ if we want to get information on the effect size for $\\beta_i$.  \n",
    "\n",
    "Second, the information gained will generally increase with time after treatment.  In other words, if we want to accurately measure a slope in the presence of noise, we should place two data points as far apart from each other as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative information gain\n",
    "\n",
    "One less obvious takeaway is that the expected value of the information over the prior depends only on the prior distribution of the noise terms, $\\sigma^2$, and not the population-level terms, $\\beta$.  If we want to incorporate some measure of information gain that is relative to what we already know (our prior), then we could look at the product of the information and the prior covariance.  Let's define the normalized information gain from observing the treatment, $x_\\mathrm{tx}$ of a patient with covariates $x_\\mathrm{tx}$ after time $t$.\n",
    "\n",
    "$$ \\mathcal{I}(x) = \\mathrm{Cov}(\\Theta) \\cdot \\int I(\\theta | x) \\ P(\\theta) \\ \\mathrm{d}\\theta$$ \n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mathrm{Cov}(\\Theta) = \\int (\\theta - \\mu_\\theta) \\cdot (\\theta - \\mu_\\theta)^T P(\\theta) \\ \\mathrm{d}\\theta $$\n",
    "\n",
    "is the covariance matrix for the prior distribution, $P(\\theta)$, and $\\mu_\\theta$ is the mean of the prior.\n",
    "\n",
    "We can use a wide range of invariants of the information matrix as a scalar measure of information gain (see for example the [Wikipedia article on optimal design](https://en.wikipedia.org/wiki/Optimal_design#Minimizing_the_variance_of_estimators)).  The trace, or the sum of the diagonal terms, is one particularly easy to compute measure.  Another scalar invariant measure of this matrix would be the determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain in action\n",
    "\n",
    "Let's see what this looks like in a few different scenarios.\n",
    "\n",
    "First we'll set up a couple convenience functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:16:29.180000-07:00",
     "start_time": "2019-08-02T16:16:29.174Z"
    }
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LinearAlgebra: diag, det, tr, dot, eigvals\n",
    "using Statistics: mean, std, cov\n",
    "using StatsBase: Histogram, fit, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T08:55:00.812000-07:00",
     "start_time": "2019-08-02T15:54:54.298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fisher (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function pdet(A)\n",
    "    \"\"\"\n",
    "    The pseudodeterminant of A is equal to the product of all non-zero\n",
    "    eigenvalues.\n",
    "    \"\"\"\n",
    "    λ = eigvals(A)\n",
    "    return prod(λ[abs.(λ) .>= 2 * eps()])\n",
    "end\n",
    "\n",
    "function blockdiag(A...)\n",
    "    \"\"\"\n",
    "    Creates a block diagonal matrix from input matrices in A\n",
    "    \"\"\"\n",
    "    if length(A) == 1\n",
    "        return A\n",
    "    end\n",
    "    N_rows = sum([size(matrix)[1] for matrix in A])\n",
    "    N_cols = sum([size(matrix)[2] for matrix in A])\n",
    "    new_matrix = zeros(N_rows, N_cols)\n",
    "    row_start = 1\n",
    "    col_start = 1\n",
    "    for (i, matrix) in enumerate(A)\n",
    "        rows, cols = size(matrix)\n",
    "        row_end = row_start + rows - 1\n",
    "        col_end = col_start + cols - 1\n",
    "        new_matrix[row_start:row_end, col_start:col_end] = matrix\n",
    "        row_start = row_end + 1\n",
    "        col_start = col_end + 1\n",
    "    end\n",
    "    return new_matrix\n",
    "end\n",
    "\n",
    "function fisher(θ_v, t, x_bm, x_tx)\n",
    "    \"\"\"\n",
    "    Compute the fisher information from\n",
    "    θ_v : array of total variance (σ2_0 + σ2_1 + σ2_ϵ) prior draws\n",
    "    t : time after treatment\n",
    "    x_bm : array of biomarker covariates\n",
    "    x_tx : array of treatment covariates\n",
    "    \"\"\"\n",
    "    x_int = [bm * tx for bm in x_bm for tx in x_tx]\n",
    "    N_bm = length(x_bm)\n",
    "    N_tx = length(x_tx)\n",
    "    N_int = N_bm * N_tx\n",
    "    N_parameters = 2 + N_bm + N_tx + N_int + 3\n",
    "    N_samples = length(θ_v)\n",
    "    x = cat([1.0, t], x_bm, x_tx, x_int; dims=1)\n",
    "    I = zeros(N_samples, N_parameters, N_parameters)\n",
    "    for i in 1:N_samples\n",
    "        v = θ_v[i]\n",
    "        I_ββ = x * inv(v) * transpose(x)\n",
    "        I_σ2σ2 = 0.5 * inv(v) ^ 2 * [1 t^2 1; t^2 t^4 t^2; 1 t^2 1]\n",
    "        I[i, :, :] = blockdiag(I_ββ, I_σ2σ2)\n",
    "    end\n",
    "    if N_samples == 1\n",
    "        return dropdims(I, dims=1)\n",
    "    end\n",
    "    return I\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at a simple case of two biomarker covariates and two treatments.  We'll use contrast coding for the biomarkers (+1 if present, -1 if not present) and indicator variables (+1 if present, 0 if not present) for the treatments.\n",
    "\n",
    "For now we're not so worried about the time dynamics so we'll just set $t = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T08:55:02.393000-07:00",
     "start_time": "2019-08-02T15:55:02.171Z"
    }
   },
   "outputs": [],
   "source": [
    "N_bm = 2\n",
    "N_tx = 2\n",
    "N_int = N_bm + N_tx\n",
    "N_parameters = 2 + N_bm + N_tx + N_int + 3\n",
    "t = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-information prior\n",
    "\n",
    "Let's assume a set of wide priors like we might have before seeing many patients.  We'll have a normal prior over effect parameters, centered at 0, with a spread of 30 (arbitrary-ish units).  For the variance terms we'll use a log-normal prior with a mean of 10 and a standard deviation of about 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:11.446000-07:00",
     "start_time": "2019-08-02T16:44:11.400Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_β = 0.0\n",
    "scale_β = 30.0\n",
    "mean_σ2 = 10.0\n",
    "scale_σ2 = 0.1\n",
    "\n",
    "μ_θ = cat(mean_β * ones(N_parameters - 3), mean_σ2 * ones(3), dims=1)\n",
    "σ_θ = cat(scale_β * ones(N_parameters - 3), scale_σ2 * ones(3), dims=1)\n",
    "\n",
    "N_samples = 10000\n",
    "\n",
    "prior = Array{Float64, 2}(undef, N_samples, N_parameters)\n",
    "for i in 1:N_parameters\n",
    "    if i < N_parameters - 2\n",
    "        # normal prior for effect size terms\n",
    "        prior[:, i] = μ_θ[i] .+ σ_θ[i] * randn(N_samples)\n",
    "    else\n",
    "        # log normal prior for variance terms\n",
    "        prior[:, i] = exp.(log(μ_θ[i]) .+ σ_θ[i] * randn(N_samples))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After drawing samples from our prior, the covariance matrix captures the relative uncertainty in the parameters.  Higher values of the variance mean a more uncertain parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:12.324000-07:00",
     "start_time": "2019-08-02T16:44:12.317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×13 Array{Float64,2}:\n",
       " 889.349       -2.97196   -12.1252     …   0.218716     0.185449  \n",
       "  -2.97196    911.921      -4.40399       -0.497496    -0.49234   \n",
       " -12.1252      -4.40399   896.29          -0.0910778    0.346473  \n",
       " -10.7395      -8.39495     3.4048        -0.260282     0.0218153 \n",
       "   4.12157     14.2729     10.3347        -0.0470188    0.630127  \n",
       "  -5.2368       4.44168     0.779624   …  -0.323813     0.184019  \n",
       "   1.5815      13.1743    -11.6491        -0.271295     0.513559  \n",
       " -12.3392      -2.37339     9.46388       -0.122911    -0.0832052 \n",
       "   7.93354      1.27571   -11.762         -0.0577343   -0.174346  \n",
       "  -8.78232     12.3374      4.76035       -0.666375    -0.047597  \n",
       "   0.0456187   -0.407741   -0.0458951  …  -0.00828818  -0.0091964 \n",
       "   0.218716    -0.497496   -0.0910778      1.03934      0.00104094\n",
       "   0.185449    -0.49234     0.346473       0.00104094   1.01023   "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_prior = cov(prior; dims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As to be expected from the specified prior, the square root of the diagonal terms represent the original scale parameters of the prior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:13.250000-07:00",
     "start_time": "2019-08-02T16:44:13.243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Array{Float64,1}:\n",
       " 29.821960011246986 \n",
       " 30.198023310270607 \n",
       " 29.938099249901477 \n",
       " 30.287773737513852 \n",
       " 30.133947276968648 \n",
       " 30.157517702425746 \n",
       " 29.687303803111924 \n",
       " 29.708961660355943 \n",
       " 29.977099611950525 \n",
       " 30.01822511999994  \n",
       "  1.0141675397549579\n",
       "  1.019479140818277 \n",
       "  1.0051009011228227"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt.(diag(cov_prior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:10:35.498000-07:00",
     "start_time": "2019-08-02T02:10:35.375Z"
    }
   },
   "source": [
    "To calculate the information, we only need the total variance from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:45:22.095000-07:00",
     "start_time": "2019-08-02T16:45:22.086Z"
    }
   },
   "outputs": [],
   "source": [
    "v = dropdims(sum(prior[:, end - 2:end], dims=2), dims=2)\n",
    "histogram(v, label=\"\", xlabel=\"Prior total variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small set of cases so let's look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:16.452000-07:00",
     "start_time": "2019-08-02T16:44:16.448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Array{Array{Int64,1},1},1}:\n",
       " [[1, 1], [1, 0]]  \n",
       " [[1, 1], [0, 1]]  \n",
       " [[1, -1], [1, 0]] \n",
       " [[1, -1], [0, 1]] \n",
       " [[-1, 1], [1, 0]] \n",
       " [[-1, 1], [0, 1]] \n",
       " [[-1, -1], [1, 0]]\n",
       " [[-1, -1], [0, 1]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases = [\n",
    "    [[1, 1], [1, 0]],\n",
    "    [[1, 1], [0, 1]],\n",
    "    [[1, -1], [1, 0]],\n",
    "    [[1, -1], [0, 1]],\n",
    "    [[-1, 1], [1, 0]],\n",
    "    [[-1, 1], [0, 1]],\n",
    "    [[-1, -1], [1, 0]],\n",
    "    [[-1, -1], [0, 1]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:17.989000-07:00",
     "start_time": "2019-08-02T16:44:16.937Z"
    }
   },
   "outputs": [],
   "source": [
    "I = map(i -> fisher(v, t, cases[i][1], cases[i][2]), 1:length(cases));\n",
    "traces = map(j -> map(i -> tr(I[j][i, :, :] * cov_prior), 1:length(v)), 1:length(cases));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:45:32.841000-07:00",
     "start_time": "2019-08-02T16:45:32.790Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot()\n",
    "for i in 1:length(cases)\n",
    "    h = normalize(fit(Histogram, traces[i], nbins=20), mode=:pdf)\n",
    "    plot!(h.edges[1][2:end], h.weights, label=\"Case $i\", lw=2)\n",
    "end\n",
    "plot!(xlabel=\"Trace(I)\", label=\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:13:24.941000-07:00",
     "start_time": "2019-08-02T16:13:24.443Z"
    }
   },
   "source": [
    "For each of the lines in the figure above is a PDF of the trace of the normalized information over the prior distribution for a given case of $x_\\mathrm{bm}$ and $x_\\mathrm{tx}$.  Since the information is only dependent on the prior variance and the prior covariance is the same for all fixed effects, none of the cases gives any more information than any other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more informative prior\n",
    "\n",
    "Now let's assume a set of wide zero-centered priors for all effect size parameters except for one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:37.641000-07:00",
     "start_time": "2019-08-02T16:44:37.594Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_β = 0.0\n",
    "scale_β = 30.0\n",
    "mean_σ2 = 10.0\n",
    "scale_σ2 = 0.1\n",
    "\n",
    "μ_θ = cat(mean_β * ones(N_parameters - 3), mean_σ2 * ones(3), dims=1)\n",
    "σ_θ = cat(scale_β * ones(N_parameters - 3), scale_σ2 * ones(3), dims=1)\n",
    "\n",
    "# set an informative prior over the interaction between bm 1 and tx 1\n",
    "μ_θ[7] = 10.0\n",
    "σ_θ[7] = 15.0\n",
    "\n",
    "N_samples = 10000\n",
    "\n",
    "prior = Array{Float64, 2}(undef, N_samples, N_parameters)\n",
    "for i in 1:N_parameters\n",
    "    if i < N_parameters - 2\n",
    "        # normal prior for effect size terms\n",
    "        prior[:, i] = μ_θ[i] .+ σ_θ[i] * randn(N_samples)\n",
    "    else\n",
    "        # log normal prior for variance terms\n",
    "        prior[:, i] = exp.(log(μ_θ[i]) .+ σ_θ[i] * randn(N_samples))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now the prior effect size for the first interaction term (the 7th index starting at 1) has significantly narrower distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:42.082000-07:00",
     "start_time": "2019-08-02T16:44:42.075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Array{Float64,1}:\n",
       " 30.425887191817324\n",
       " 29.874045590301595\n",
       " 30.237410191363423\n",
       " 30.085890957833623\n",
       " 30.22872057583287 \n",
       " 29.700032673358397\n",
       " 15.076636841400346\n",
       " 30.08776316097902 \n",
       " 30.267595539867393\n",
       " 29.647429816759566\n",
       "  1.012546203163566\n",
       "  1.016487239148962\n",
       "  0.989973456469391"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_prior = cov(prior; dims=1)\n",
    "sqrt.(diag(cov_prior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T19:10:35.498000-07:00",
     "start_time": "2019-08-02T02:10:35.375Z"
    }
   },
   "source": [
    "The variance is the same as before, so we'll have the same information matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:44:43.997000-07:00",
     "start_time": "2019-08-02T16:44:43.051Z"
    }
   },
   "outputs": [],
   "source": [
    "v = dropdims(sum(prior[:, end - 2:end], dims=2), dims=2)\n",
    "I = map(i -> fisher(v, t, cases[i][1], cases[i][2]), 1:length(cases))\n",
    "traces = map(j -> map(i -> tr(I[j][i, :, :] * cov_prior), 1:length(v)), 1:length(cases));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T09:45:28.084000-07:00",
     "start_time": "2019-08-02T16:45:28.018Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 : x_bm = [1, 1], x_tx = [1, 0], <trace> = 190.41\n",
      "Case 2 : x_bm = [1, 1], x_tx = [0, 1], <trace> = 213.08\n",
      "Case 3 : x_bm = [1, -1], x_tx = [1, 0], <trace> = 190.55\n",
      "Case 4 : x_bm = [1, -1], x_tx = [0, 1], <trace> = 213.32\n",
      "Case 5 : x_bm = [-1, 1], x_tx = [1, 0], <trace> = 185.65\n",
      "Case 6 : x_bm = [-1, 1], x_tx = [0, 1], <trace> = 209.03\n",
      "Case 7 : x_bm = [-1, -1], x_tx = [1, 0], <trace> = 190.3\n",
      "Case 8 : x_bm = [-1, -1], x_tx = [0, 1], <trace> = 210.88\n"
     ]
    }
   ],
   "source": [
    "plot()\n",
    "for i in 1:length(cases)\n",
    "    x_bm, x_tx = cases[i]\n",
    "    mean_trace = round(mean(traces[i]), digits=2)\n",
    "    println(\"Case $i : x_bm = $x_bm, x_tx = $x_tx, <trace> = $mean_trace\")\n",
    "    h = normalize(fit(Histogram, traces[i], nbins=20), mode=:pdf)\n",
    "    plot!(h.edges[1][2:end], h.weights, label=\"Case $i\", lw=2)\n",
    "end\n",
    "plot!(xlabel=\"Trace(I)\", label=\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that four cases (2, 4, 6, 8) provide more relative information than the others.  These correspond exactly to the cases involving treatment 2 rather than treatment 1.  Since we already have more information on treatment 1 from the narrower prior distribution on the interaction effect between treatment 1 and biomarker 1, any cases with a different treatment provide more relative information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
